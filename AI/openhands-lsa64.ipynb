{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os, sys, gc\n",
    "import time\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "from tqdm.auto import tqdm\n",
    "import multiprocessing\n",
    "from joblib import Parallel, delayed\n",
    "from natsort import natsorted\n",
    "from glob import glob\n",
    "import math\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_holistic = mp.solutions.holistic\n",
    "\n",
    "N_FACE_LANDMARKS = 468\n",
    "N_BODY_LANDMARKS = 33\n",
    "N_HAND_LANDMARKS = 21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Counter(object):\n",
    "    # https://stackoverflow.com/a/47562583/\n",
    "    def __init__(self, initval=0):\n",
    "        self.val = multiprocessing.RawValue(\"i\", initval)\n",
    "        self.lock = multiprocessing.Lock()\n",
    "\n",
    "    def increment(self):\n",
    "        with self.lock:\n",
    "            self.val.value += 1\n",
    "\n",
    "    @property\n",
    "    def value(self):\n",
    "        return self.val.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_body_landmarks(component, n_points):\n",
    "    kps = np.zeros((n_points, 3))\n",
    "    conf = np.zeros(n_points)\n",
    "    if component is not None:\n",
    "        landmarks = component.landmark\n",
    "        kps = np.array([[p.x, p.y, p.z] for p in landmarks])\n",
    "        conf = np.array([p.visibility for p in landmarks])\n",
    "    return kps, conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_other_landmarks(component, n_points):\n",
    "    kps = np.zeros((n_points, 3))\n",
    "    conf = np.zeros(n_points)\n",
    "    if component is not None:\n",
    "        landmarks = component.landmark\n",
    "        kps = np.array([[p.x, p.y, p.z] for p in landmarks])\n",
    "        conf = np.ones(n_points)\n",
    "    return kps, conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_holistic_keypoints(\n",
    "    frames, holistic=mp_holistic.Holistic(static_image_mode=False, model_complexity=2)\n",
    "):\n",
    "    \"\"\"\n",
    "    For videos, it's optimal to create with `static_image_mode=False` for each video.\n",
    "    https://google.github.io/mediapipe/solutions/holistic.html#static_image_mode\n",
    "    \"\"\"\n",
    "\n",
    "    keypoints = []\n",
    "    confs = []\n",
    "\n",
    "    for frame in frames:\n",
    "        results = holistic.process(frame)\n",
    "\n",
    "        body_data, body_conf = process_body_landmarks(\n",
    "            results.pose_landmarks, N_BODY_LANDMARKS\n",
    "        )\n",
    "        face_data, face_conf = process_other_landmarks(\n",
    "            results.face_landmarks, N_FACE_LANDMARKS\n",
    "        )\n",
    "        lh_data, lh_conf = process_other_landmarks(\n",
    "            results.left_hand_landmarks, N_HAND_LANDMARKS\n",
    "        )\n",
    "        rh_data, rh_conf = process_other_landmarks(\n",
    "            results.right_hand_landmarks, N_HAND_LANDMARKS\n",
    "        )\n",
    "\n",
    "        data = np.concatenate([body_data, face_data, lh_data, rh_data])\n",
    "        conf = np.concatenate([body_conf, face_conf, lh_conf, rh_conf])\n",
    "\n",
    "        keypoints.append(data)\n",
    "        confs.append(conf)\n",
    "\n",
    "    # TODO: Reuse the same object when this issue is fixed: https://github.com/google/mediapipe/issues/2152\n",
    "    holistic.reset()\n",
    "    del holistic\n",
    "    gc.collect()\n",
    "\n",
    "    keypoints = np.stack(keypoints)\n",
    "    confs = np.stack(confs)\n",
    "    return keypoints, confs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_keypoints_for_frames(frames, save_path):\n",
    "\n",
    "    pose_kps, pose_confs = get_holistic_keypoints(frames)\n",
    "    body_kps = np.concatenate([pose_kps[:, :33, :], pose_kps[:, 501:, :]], axis=1)\n",
    "\n",
    "    confs = np.concatenate([pose_confs[:, :33], pose_confs[:, 501:]], axis=1)\n",
    "\n",
    "    d = {\"keypoints\": body_kps, \"confidences\": confs}\n",
    "\n",
    "    with open(save_path + \".pkl\", \"wb\") as f:\n",
    "        pickle.dump(d, f, protocol=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_frames_from_video(video_path):\n",
    "    frames = []\n",
    "    vidcap = cv2.VideoCapture(video_path)\n",
    "    while vidcap.isOpened():\n",
    "        success, img = vidcap.read()\n",
    "        if not success:\n",
    "            break\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        # img = cv2.resize(img, (640, 480))\n",
    "        frames.append(img)\n",
    "\n",
    "    vidcap.release()\n",
    "    # cv2.destroyAllWindows()\n",
    "    return np.asarray(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_frames_from_folder(frames_folder, patterns=[\"*.jpg\"]):\n",
    "    images = []\n",
    "    for pattern in patterns:\n",
    "        images.extend(glob(f\"{frames_folder}/{pattern}\"))\n",
    "    images = natsorted(list(set(images)))  # remove dupes\n",
    "    if not images:\n",
    "        exit(f\"ERROR: No frames in folder: {frames_folder}\")\n",
    "\n",
    "    frames = []\n",
    "    for img_path in images:\n",
    "        img = cv2.imread(img_path)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        frames.append(img)\n",
    "\n",
    "    return np.asarray(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_keypoints_for_video(video_path, save_path):\n",
    "    if not os.path.isfile(video_path):\n",
    "        print(\"SKIPPING MISSING FILE:\", video_path)\n",
    "        return\n",
    "    frames = load_frames_from_video(video_path)\n",
    "    gen_keypoints_for_frames(frames, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_keypoints_for_folder(folder, save_path, file_patterns):\n",
    "    frames = load_frames_from_folder(folder, file_patterns)\n",
    "    gen_keypoints_for_frames(frames, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_pose(dataset, save_folder, worker_index, num_workers, counter):\n",
    "    num_splits = math.ceil(len(dataset) / num_workers)\n",
    "    end_index = min((worker_index + 1) * num_splits, len(dataset))\n",
    "    for index in range(worker_index * num_splits, end_index):\n",
    "        imgs, label, video_id = dataset.read_data(index)\n",
    "        save_path = os.path.join(save_folder, video_id)\n",
    "        os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
    "        gen_keypoints_for_frames(imgs, save_path)\n",
    "        counter.increment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dump_pose_for_dataset(\n",
    "    dataset, save_folder, num_workers=multiprocessing.cpu_count()\n",
    "):\n",
    "    os.makedirs(save_folder, exist_ok=True)\n",
    "    processes = []\n",
    "    counter = Counter()\n",
    "    for i in tqdm(range(num_workers), desc=\"Creating sub-processes...\"):\n",
    "        p = multiprocessing.Process(\n",
    "            target=generate_pose, args=(dataset, save_folder, i, num_workers, counter)\n",
    "        )\n",
    "        p.start()\n",
    "        processes.append(p)\n",
    "\n",
    "    total_samples = len(dataset)\n",
    "    with tqdm(total=total_samples) as pbar:\n",
    "        while counter.value < total_samples:\n",
    "            pbar.update(counter.value - pbar.n)\n",
    "            time.sleep(2)\n",
    "\n",
    "    for i in range(num_workers):\n",
    "        processes[i].join()\n",
    "    print(f\"Pose data successfully saved to: {save_folder}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_cores = multiprocessing.cpu_count()\n",
    "\n",
    "Top_DIR = \"archive\"\n",
    "SAVE_DIR = \"holistic_poses\"\n",
    "for DIR in os.listdir(Top_DIR):\n",
    "    os.makedirs(os.path.join(SAVE_DIR,DIR), exist_ok=True)\n",
    "\n",
    "    file_paths = []\n",
    "    save_paths = []\n",
    "    for file in os.listdir(os.path.join(Top_DIR,DIR)):\n",
    "        file_paths.append(os.path.join(Top_DIR,DIR, file))\n",
    "        save_paths.append(os.path.join(SAVE_DIR,DIR, file.replace(\".mp4\", \"\")))\n",
    "\n",
    "    \n",
    "    for path, save_path in tqdm(zip(file_paths, save_paths)):\n",
    "        gen_keypoints_for_video(path, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mkdir output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {\"001\":\"adress\",\"002\":\"and\",\"003\":\"anise\",\"004\":\"banana\",\"005\":\"berell\",\"006\":\"birth certificate\",\"007\":\"cinnamon\",\"008\":\"coffee\",\"009\":\"cold\",\"010\":\"deaf\",\"011\":\"doing\",\"012\":\"drink\",\"013\":\"fenugreek\",\"014\":\"fine\",\"015\":\"glass\",\"016\":\"hello\",\"017\":\"help\",\"018\":\"hot\",\"019\":\"How are you\",\"020\":\"How much\",\"021\":\"in\",\"022\":\"juice\",\"023\":\"lemon\",\"024\":\"mango\",\"025\":\"me\",\"026\":\"milk\",\"027\":\"mint\",\"028\":\"money\",\"029\":\"my\",\"030\":\"name\",\"031\":\"need\",\"032\":\"nescafe\",\"033\":\"new\",\"034\":\"no\",\"035\":\"number\",\"036\":\"ok\",\"037\":\"on\",\"038\":\"or\",\"039\":\"orange\",\"040\":\"pepsi\",\"041\":\"problem\",\"042\":\"question\",\"043\":\"Roselle\",\"044\":\"spoon\",\"045\":\"strawberry\",\"046\":\"tea\",\"047\":\"Thank god\",\"048\":\"wait\",\"049\":\"water\",\"050\":\"what\",\"051\":\"yes\",\"052\":\"you\",\"053\":\"your\",\"054\":\"Your health is fine\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "swapped_dict = {value: key for key, value in d.items()}\n",
    "\n",
    "print(swapped_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import shutil\n",
    "data = \"/kaggle/input/holistic/holistic_poses/holistic_poses\"\n",
    "for word in os.listdir(data):\n",
    "    id = swapped_dict.get(word)\n",
    "    if id:\n",
    "        print(word,id)\n",
    "        i=0\n",
    "        for pos in os.listdir(os.path.join(data,word)):\n",
    "            if i<=70:\n",
    "                shutil.copy(os.path.join(data,word,pos),\"output/\"+id+\"_001_0\"+str(i)+\".pkl\")\n",
    "                i+=1\n",
    "            elif i <90:\n",
    "                shutil.copy(os.path.join(data,word,pos),\"output/\"+id+\"_009_0\"+str(i)+\".pkl\")\n",
    "                i+=1\n",
    "            else:\n",
    "                shutil.copy(os.path.join(data,word,pos),\"output/\"+id+\"_010_0\"+str(i)+\".pkl\")\n",
    "                i+=1\n",
    "    else:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_model():\n",
    "    !pip install openhands\n",
    "    !rm /kaggle/working/OpenHands/openhands/models/ssl/dpc_rnn.py\n",
    "    !cp /kaggle/input/holistic/dpc_rnn.py /kaggle/working/OpenHands/openhands/models/ssl/\n",
    "    !rm /kaggle/working/OpenHands/openhands/core/exp_utils.py\n",
    "    !cp /kaggle/input/holistic/exp_utils.py /kaggle/working/OpenHands/openhands/core/\n",
    "    !rm /kaggle/working/OpenHands/openhands/apis/classification_model.py\n",
    "    !cp /kaggle/input/test-data/classification_model.py /kaggle/working/OpenHands/openhands/apis/\n",
    "    !rm /kaggle/working/OpenHands/openhands/apis/inference.py\n",
    "    !cp /kaggle/input/test-data/inference.py /kaggle/working/OpenHands/openhands/apis/\n",
    "    %cd OpenHands/\n",
    "    !python setup.py install\n",
    "    %cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install git+https://github.com/PytorchLightning/lightning-bolts.git@master --upgrade\n",
    "!git clone https://github.com/AI4Bharat/OpenHands.git\n",
    "init_model()\n",
    "init_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E:\\project_material\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\20155\\anaconda3\\envs\\GP\\lib\\site-packages\\IPython\\core\\magics\\osm.py:417: UserWarning: using dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1.4.2\n"
     ]
    }
   ],
   "source": [
    "import openhands\n",
    "print(openhands.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from omegaconf import OmegaConf\n",
    "import openhands\n",
    "from openhands.apis.classification_model import ClassificationModel\n",
    "from openhands.core.exp_utils import get_trainer\n",
    "\n",
    "cfg = OmegaConf.load(\"/kaggle/input/test-data/decoupled_gcn.yaml\")\n",
    "trainer = get_trainer(cfg)\n",
    "\n",
    "model = ClassificationModel(cfg=cfg, trainer=trainer)\n",
    "model.init_from_checkpoint_if_available()\n",
    "model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import FileLink\n",
    "FileLink(r'best_model.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!zip best_model.zip /kaggle/working/experiments/lsa64/sl_gcn/epoch=47-step=1776.ckpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.data.test_pipeline.dataset.root_dir='Model/temp/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\20155\\anaconda3\\envs\\GP\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 53 classes in test splits\n",
      "Loading checkpoint from: E:/project_material/Model/epoch91.ckpt\n",
      "Thank god:\tModel/test\\01_0001_(10_03_21_20_37_17)_c.pkl\n",
      "Thank god:\tModel/test\\01_0002_(10_03_21_20_53_42)_c.pkl\n",
      "help:\tModel/test\\VID-20240228-WA0009.pkl\n",
      "birth certificate:\tModel/test\\VID-20240228-WA0011.pkl\n",
      "How much:\tModel/test\\VID20230309141046.pkl\n",
      "adress:\tModel/test\\WIN_20240301_15_47_18_Pro.pkl\n",
      "How much:\tModel/test\\WIN_20240301_15_57_57_Pro.pkl\n",
      "Avg time per iteration: 956.0108184814453 ms\n"
     ]
    }
   ],
   "source": [
    "from omegaconf import OmegaConf\n",
    "from openhands.apis.inference import InferenceModel\n",
    "import openhands\n",
    "\n",
    "cfg = OmegaConf.load(\"Model/decoupled_gcn.yaml\")\n",
    "model = InferenceModel(cfg=cfg)\n",
    "model.init_from_checkpoint_if_available()\n",
    "if cfg.data.test_pipeline.dataset.inference_mode:\n",
    "   pred = model.test_inference()\n",
    "else:\n",
    "    model.compute_test_accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = OmegaConf.load(\"/kaggle/input/test-data/decoupled_gcn.yaml\")\n",
    "model = InferenceModel(cfg=cfg)\n",
    "model.init_from_checkpoint_if_available()\n",
    "model.compute_test_accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 4399305,
     "sourceId": 7553385,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4406354,
     "sourceId": 7651044,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4476228,
     "sourceId": 7688065,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30648,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
