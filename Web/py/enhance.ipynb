{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ba6b5e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.12.1 (tags/v3.12.1:2305ca5, Dec  7 2023, 22:03:25) [MSC v.1937 64 bit (AMD64)]\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'mediapipe'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtime\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmediapipe\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmp\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtqdm\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mauto\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tqdm\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmultiprocessing\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'mediapipe'"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.version)\n",
    "import cv2\n",
    "import os, sys, gc\n",
    "import time\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "from tqdm.auto import tqdm\n",
    "import multiprocessing\n",
    "from joblib import Parallel, delayed\n",
    "from natsort import natsorted\n",
    "from glob import glob\n",
    "import math\n",
    "import pickle\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e54a02",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "67cf7197",
   "metadata": {},
   "source": [
    "import cv2\n",
    "import os, sys, gc\n",
    "import time\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "from tqdm.auto import tqdm\n",
    "import multiprocessing\n",
    "from joblib import Parallel, delayed\n",
    "from natsort import natsorted\n",
    "from glob import glob\n",
    "import math\n",
    "import pickle\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a43c116",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m mp_holistic \u001b[38;5;241m=\u001b[39m \u001b[43mmp\u001b[49m\u001b[38;5;241m.\u001b[39msolutions\u001b[38;5;241m.\u001b[39mholistic\n\u001b[0;32m      3\u001b[0m N_FACE_LANDMARKS \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m468\u001b[39m\n\u001b[0;32m      4\u001b[0m N_BODY_LANDMARKS \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m33\u001b[39m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'mp' is not defined"
     ]
    }
   ],
   "source": [
    "mp_holistic = mp.solutions.holistic\n",
    "\n",
    "N_FACE_LANDMARKS = 468\n",
    "N_BODY_LANDMARKS = 33\n",
    "N_HAND_LANDMARKS = 21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca463bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Counter(object):\n",
    "    # https://stackoverflow.com/a/47562583/\n",
    "    def __init__(self, initval=0):\n",
    "        self.val = multiprocessing.RawValue(\"i\", initval)\n",
    "        self.lock = multiprocessing.Lock()\n",
    "\n",
    "    def increment(self):\n",
    "        with self.lock:\n",
    "            self.val.value += 1\n",
    "\n",
    "    @property\n",
    "    def value(self):\n",
    "        return self.val.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a2baa60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_body_landmarks(component, n_points):\n",
    "    kps = np.zeros((n_points, 3))\n",
    "    conf = np.zeros(n_points)\n",
    "    if component is not None:\n",
    "        landmarks = component.landmark\n",
    "        kps = np.array([[p.x, p.y, p.z] for p in landmarks])\n",
    "        conf = np.array([p.visibility for p in landmarks])\n",
    "    return kps, conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14322863",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_other_landmarks(component, n_points):\n",
    "    kps = np.zeros((n_points, 3))\n",
    "    conf = np.zeros(n_points)\n",
    "    if component is not None:\n",
    "        landmarks = component.landmark\n",
    "        kps = np.array([[p.x, p.y, p.z] for p in landmarks])\n",
    "        conf = np.ones(n_points)\n",
    "    return kps, conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e116a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_holistic_keypoints(\n",
    "    frames, holistic=mp_holistic.Holistic(static_image_mode=False, model_complexity=2)\n",
    "):\n",
    "    \"\"\"\n",
    "    For videos, it's optimal to create with `static_image_mode=False` for each video.\n",
    "    https://google.github.io/mediapipe/solutions/holistic.html#static_image_mode\n",
    "    \"\"\"\n",
    "\n",
    "    keypoints = []\n",
    "    confs = []\n",
    "\n",
    "    for frame in frames:\n",
    "        results = holistic.process(frame)\n",
    "\n",
    "        body_data, body_conf = process_body_landmarks(\n",
    "            results.pose_landmarks, N_BODY_LANDMARKS\n",
    "        )\n",
    "        face_data, face_conf = process_other_landmarks(\n",
    "            results.face_landmarks, N_FACE_LANDMARKS\n",
    "        )\n",
    "        lh_data, lh_conf = process_other_landmarks(\n",
    "            results.left_hand_landmarks, N_HAND_LANDMARKS\n",
    "        )\n",
    "        rh_data, rh_conf = process_other_landmarks(\n",
    "            results.right_hand_landmarks, N_HAND_LANDMARKS\n",
    "        )\n",
    "\n",
    "        data = np.concatenate([body_data, face_data, lh_data, rh_data])\n",
    "        conf = np.concatenate([body_conf, face_conf, lh_conf, rh_conf])\n",
    "\n",
    "        keypoints.append(data)\n",
    "        confs.append(conf)\n",
    "\n",
    "    # TODO: Reuse the same object when this issue is fixed: https://github.com/google/mediapipe/issues/2152\n",
    "    holistic.reset()\n",
    "    del holistic\n",
    "    gc.collect()\n",
    "\n",
    "    keypoints = np.stack(keypoints)\n",
    "    confs = np.stack(confs)\n",
    "    return keypoints, confs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b7cd308",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_keypoints_for_frames(frames, save_path):\n",
    "\n",
    "    pose_kps, pose_confs = get_holistic_keypoints(frames)\n",
    "    body_kps = np.concatenate([pose_kps[:, :33, :], pose_kps[:, 501:, :]], axis=1)\n",
    "\n",
    "    confs = np.concatenate([pose_confs[:, :33], pose_confs[:, 501:]], axis=1)\n",
    "\n",
    "    d = {\"keypoints\": body_kps, \"confidences\": confs}\n",
    "\n",
    "#     with open(save_path + \".pkl\", \"wb\") as f:\n",
    "#         pickle.dump(d, f, protocol=4)\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb73a386",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_frames_from_video(video_path):\n",
    "    frames = []\n",
    "    vidcap = cv2.VideoCapture(video_path)\n",
    "    while vidcap.isOpened():\n",
    "        success, img = vidcap.read()\n",
    "        if not success:\n",
    "            break\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        # img = cv2.resize(img, (640, 480))\n",
    "        frames.append(img)\n",
    "\n",
    "    vidcap.release()\n",
    "    # cv2.destroyAllWindows()\n",
    "    return np.asarray(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b956842",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_keypoints_for_video(video_path, save_path):\n",
    "    if not os.path.isfile(video_path):\n",
    "        print(\"SKIPPING MISSING FILE:\", video_path)\n",
    "        return\n",
    "    frames = load_frames_from_video(video_path)\n",
    "    gen_keypoints_for_frames(frames, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f47b4d8c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
